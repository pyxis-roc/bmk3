#!/usr/bin/python3
# -*- mode: python -*-

import argparse
import bmk3
import os
import sys
import bmk3.cmdscript as cmdscript
import logging
import glob
import fnmatch
import re
import textwrap
import bmk3.rulerunners as rulerunners
from bmk3 import logutils
import datetime
import json

logger = logging.getLogger('bmk3')

def find_bmk3():
    paths = ['.']

    while len(paths):
        try:
            with os.scandir(paths[0]) as l:
                for f in l:
                    if f.is_dir():
                        paths.append(f)
                    elif f.is_file() and f.name == 'bmk3.yaml':
                        yield f.path[2:] # drop ./ at front
        except PermissionError as e:
            logger.error(str(e))

        del paths[0]

def rule_globs_to_re(r):
    xp = [fnmatch.translate(rr) for rr in r]
    return re.compile("|".join([x for x in xp]))

def make_prefix_globs(r):
    # note that rules must be python identifiers, but suffixing with
    # variable contents can change this. So there is no way to detect
    # reliably that a rule prefix supplied on the command line
    # contains no globs. To prevent accidental globbing beyond prefix
    # expansion, we escape all glob characters.

    pg = [glob.escape(x) + "*" for x in r]

    return pg

def dump_outliers(cmdscripts, count, success):
    # if all runs were successful or failed, don't print this list
    if success == 0:
        logger.info(f"All rules failed.")
        return

    if success == count:
        logger.info(f"All rules succeeded.")
        return

    if success > count - success:
        # if most benchmarks succeeded
        crit = lambda x: not x.result.success # select failures
        msg = "failed"
    else:
        # if most benchmarks failed
        crit = lambda x: x.result.success # select successes
        msg = "succeeded"

    for cs in cmdscripts:
        if crit(cs):
            logger.info(f"{cs.name} {msg}.")

def dump_run_stats(cmdscripts, outfile):
    out = {}
    for cs in cmdscripts:
        out[cs.name] = cs.get_stats()

    with open(outfile, "w") as f:
        json.dump(out, fp=f, indent=2)

if __name__ == "__main__":
    p = argparse.ArgumentParser(description="Run a bmk3 script")
    p.add_argument("-g", dest="globrules", help="Treat rule prefixes as glob patterns",
                   action="store_true")
    p.add_argument("-v", dest="variables", help="Add variable", default=[], action="append")
    p.add_argument("-n", dest="dryrun", help="Dry run", action="store_true")
    p.add_argument("-q", dest="quiet", help="Quiet", action="store_true")
    p.add_argument("-k", dest="keep", choices=['always', 'fail', 'never'],
                   help="Keep temporary files", default='fail')
    p.add_argument("-C", dest="workdir", metavar="DIR", help="Change to DIR")
    p.add_argument("-l", dest="logfile", metavar="FILE", help="Log to file")
    p.add_argument("--js", dest="jsonstats", metavar="FILE", help="Store run statistics in JSON file")
    p.add_argument("-j", dest="parallel", metavar="PROCS", help="Run PROCS in parallel, 0 for number of cores", type=int)
    p.add_argument("rules", nargs="*", help="Prefixes of rules to run", default=[])

    args = p.parse_args()

    logutils.setup_logging(args.logfile, filemode='a', multiprocessing = args.parallel is not None)

    if args.workdir:
        log.debug(f"Changing to {args.workdir}")
        os.chdir(args.workdir)

    start_time = datetime.datetime.now(tz=datetime.timezone.utc)
    logger.info(f"Start at {start_time.astimezone().isoformat()} ({start_time.isoformat()})")
    bmk3files = list(find_bmk3())
    cp = os.path.commonpath(bmk3files)

    logger.info(f'Loaded {len(bmk3files)} files')
    logger.debug(f'Found {bmk3files}')

    if not len(bmk3files):
        logger.error(f"bmk3 configuration {os.getcwd()}/{args.bmk3file} does not exist.")
        sys.exit(1)

    cmdline_variables = {}
    if args.variables:
        for v in args.variables:
            vn, vv = v.split("=", 1)
            cmdline_variables[vn] = vv

    b = bmk3.BMK3()
    b.load_scripts(bmk3files, strip_prefix = cp)
    b.update_variables(cmdline_variables)
    b.expand_templates()

    if args.rules:
        if args.globrules:
            rule_re = rule_globs_to_re(args.rules)
        else:
            rule_re = rule_globs_to_re(make_prefix_globs(args.rules))
    else:
        rule_re = None

    # expand template definitions and build command scripts

    cmdscripts = []
    rulecount = 0

    try:
        for s, t, g in b.generate():
            a, c = g
            k = [t]

            if 'binary' in a: k.append(a['binary'])
            if 'input' in a: k.append(str(a['input']['name']))

            name = ':'.join(k)

            if s.ns:
                name = f"{name}[{s.ns}]"

            if '_serial' in a and a['_serial']:
                sem = a['_semaphores']
            else:
                sem = None

            if rule_re:
                if rule_re.match(name):
                    x = cmdscript.CmdScript(name, c, a, cwd = s.cwd)
                    cmdscripts.append(x)
            else:
                print(f"*** {name} serial={a['_serial']} sem={sem}")
                x = cmdscript.CmdScript(name, c, a)
                if not args.quiet:
                    print(textwrap.indent(str(x), '   '))
                x.cleanup()
                rulecount += 1
    except KeyError as err:
        logger.error(f"While expanding template, {str(err)}")
        raise
        sys.exit(1)

    if rule_re:

        if args.parallel is not None:
            logger.info(f'Using parallel execution mode with nprocs={args.parallel}')
            rr = rulerunners.ParallelRunner(args.parallel if args.parallel != 0 else None)
        else:
            rr = rulerunners.SerialRunner()

        # TODO: in serial mode, results contains the same objects as
        # cmdscripts in parallel runs, result objects are different
        # than cmdscripts

        results = rr.run_all(cmdscripts, dry_run = args.dryrun, keep_temps = args.keep, quiet = args.quiet)
        if not args.dryrun:
            count = len(results)
            success = len(list(filter(lambda x: x.result.success, results)))

            logger.info(f'COUNT: {count}, SUCCESS: {success}, FAILED: {count - success}')

            if True or (count != success):
                dump_outliers(results, count, success)

                if args.jsonstats:
                    logger.info(f"Writing run stats to {args.jsonstats}")
                    dump_run_stats(results, args.jsonstats)
        else:
            logger.info(f'COUNT: {count}')
    else:
        logger.info(f'COUNT: {rulecount}')

    end_time = datetime.datetime.now(tz=datetime.timezone.utc)

    logger.info(f"End at {end_time.astimezone().isoformat()} ({end_time.isoformat()})")
    logger.info(f"Total time {end_time - start_time}")

